# File: agent-spool-dir.conf 

# Agent(spool_dir)
spool_dir.sources = src-1
spool_dir.channels = channel-1
spool_dir.sinks = sink_to_hdfs

# Source
spool_dir.sources.src-1.type = spooldir
spool_dir.sources.src-1.spoolDir = /home/tom/bigtop/flumeSpool
spool_dir.sources.src-1.fileHeader = true

# Sinks
spool_dir.sinks.sink_to_hdfs.type = hdfs
spool_dir.sinks.sink_to_hdfs.hdfs.fileType = DataStream
spool_dir.sinks.sink_to_hdfs.hdfs.path = hdfs://localhost/user/root/flume-sinks/spool-to-hdfs
spool_dir.sinks.sink_to_hdfs.hdfs.filePrefix = custom-event
spool_dir.sinks.sink_to_hdfs.hdfs.fileSuffix = .log
spool_dir.sinks.sink_to_hdfs.hdfs.batchSize = 1000

# Channel
spool_dir.channels.channel-1.type = memory
spool_dir.channels.channel-1.capacity = 20000
spool_dir.channels.channel-1.transactionCapacity = 100

# Bind the source and sink to the channel
spool_dir.sources.src-1.channels = channel-1
spool_dir.sinks.sink_to_hdfs.channel = channel-1

#---------[ How to test this agent]---------
#Launch agent
# $ flume-ng agent -f ./agent-spool-dir.conf -n spool_dir

# I will copy all apache logs to the spool
# $ cp /home/tom/tmp/log/* /home/tom/bigtop/flumeSpool

### you should see lots of activities in the flume log
### now check hdfs server
### login to the hdfs server
# $ hdfs dfs -ls hdfs://localhost/user/root/flume-sinks/spool-to-hdfs
